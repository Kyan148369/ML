{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":325302,"sourceType":"datasetVersion","datasetId":137362},{"sourceId":7719305,"sourceType":"datasetVersion","datasetId":4508749},{"sourceId":7776815,"sourceType":"datasetVersion","datasetId":4550456},{"sourceId":7955238,"sourceType":"datasetVersion","datasetId":4678924},{"sourceId":27987,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":23559}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Trying to implemenet a basic version of segmentation and denoising over here","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:14:55.735845Z","iopub.execute_input":"2024-04-14T14:14:55.736585Z","iopub.status.idle":"2024-04-14T14:14:55.743480Z","shell.execute_reply.started":"2024-04-14T14:14:55.736551Z","shell.execute_reply":"2024-04-14T14:14:55.742341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So over here basic pipeline we have is\n1. Load the pictures from the desired dataset two diff photos \n\n2. One if we're starting with psnr we basically need to load the photo into with image_true and image_test(the noised image) (If i have photos how do we decide which is which can prolly reverse and see)\n* Basically need to plot a graph of psnr vs noise when we're increasing the amount of noise percentage wise in the pixels \n\n3. If we're doing SSIM we'll compare two photos in the following order as Bhavesh had requested and deal with them accordingly \n* Dog and cat\n* Cat and cat (diff breed)\n* Dog and Dog (diff breed)\n*Dog and Dog (same breed but diff angle/lighting)\n* Cat and Cat (same breed but diff angle/lighting)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import img_as_float, io\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.transform import resize\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom tqdm import tqdm\nimport math\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:50:29.275136Z","iopub.execute_input":"2024-04-16T04:50:29.275822Z","iopub.status.idle":"2024-04-16T04:50:37.891510Z","shell.execute_reply.started":"2024-04-16T04:50:29.275789Z","shell.execute_reply":"2024-04-16T04:50:37.890688Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Path to the text file containing the image file names\ntext_file_path = \"/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/annotations/annotations/list.txt\"\n\n# Initialize empty sets to store unique cat and dog file names\nunique_cats = set()\nunique_dogs = set()\n\n# Read the text file line by line\nwith open(text_file_path, \"r\") as file:\n    for line in file:\n        # Split the line by spaces\n        parts = line.split()\n        if len(parts) > 0:\n            # Extract the image file name (assuming it's the first part)\n            filename = parts[0]\n            # Remove any numbering before the first underscore\n            name_without_numbering = filename.split(\"_\", 1)[0]\n            # Check if the filename starts with a capital letter (cat) or a lowercase letter (dog)\n            if name_without_numbering[0].isupper():\n                unique_cats.add(name_without_numbering)\n            else:\n                unique_dogs.add(name_without_numbering)\n\n# Convert the sets to lists and print the unique cat and dog file names\nunique_cats_list = list(unique_cats)\nunique_dogs_list = list(unique_dogs)\n\nprint(\"Unique cat names list:\")\nprint(unique_cats_list)\n\nprint(\"\\nUnique dog names list:\")\nprint(unique_dogs_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:01.506221Z","iopub.execute_input":"2024-04-14T14:15:01.506701Z","iopub.status.idle":"2024-04-14T14:15:01.543921Z","shell.execute_reply.started":"2024-04-14T14:15:01.506672Z","shell.execute_reply":"2024-04-14T14:15:01.542968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom skimage import img_as_float \n\ncat_pic_1 = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/Abyssinian_1.jpg'))\ndog_pic_1 = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/samoyed_1.jpg'))\ncat_pic_1_same = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/Abyssinian_2.jpg'))\ndog_pic_1_same = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/samoyed_2.jpg'))\ncat_pic_2 = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/Persian_1.jpg'))\ndog_pic_2 = img_as_float(io.imread('/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/pug_1.jpg'))\n\n\n\nblack_pic = img_as_float(io.imread('/kaggle/input/imp-ref-photos/black_pic.png'))\nwhite_pic = img_as_float(io.imread('/kaggle/input/imp-ref-photos/white_pic.jpeg'))\nsame_dog_a = img_as_float(io.imread('/kaggle/input/imp-ref-photos/same_dog_a.png'))\nsame_dog_b = img_as_float(io.imread('/kaggle/input/imp-ref-photos/same_dog_b.png'))\nsame_dog_c = img_as_float(io.imread('/kaggle/input/imp-ref-photos/same_dog_c.png'))\nsame_dog_d = img_as_float(io.imread('/kaggle/input/imp-ref-photos/same_dog_d.png'))\n\n\n\n# Display the images\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.imshow(cat_pic_1)\nplt.title('Cat Image')\n\nplt.subplot(1, 2, 2)\nplt.imshow(dog_pic_1)\nplt.title('Dog Image')\n\nplt.show()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:01.547386Z","iopub.execute_input":"2024-04-14T14:15:01.548060Z","iopub.status.idle":"2024-04-14T14:15:02.461199Z","shell.execute_reply.started":"2024-04-14T14:15:01.548033Z","shell.execute_reply":"2024-04-14T14:15:02.460190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Function to resize and convert an image to grayscale\ndef preprocess_image(image, target_shape):\n    gray_image = rgb2gray(image)\n    resized_image = resize(gray_image, target_shape, anti_aliasing=True)\n    return resized_image\n\n# Function to compare two images using SSIM\ndef compare_images(image1, image2, target_shape):\n    image1_preprocessed = preprocess_image(image1, target_shape)\n    image2_preprocessed = preprocess_image(image2, target_shape)\n    ssim_value = ssim(image1_preprocessed, image2_preprocessed, data_range=image1_preprocessed.max() - image1_preprocessed.min())\n    return ssim_value\n\n# Sample usage\nif __name__ == \"__main__\":\n    # Load your images here (for example, using plt.imread)\n    cat_pic_1 = cat_pic_1\n    dog_pic_1 = dog_pic_1\n\n    target_shape = (100, 100)\n    ssim_value = compare_images(cat_pic_1, dog_pic_1, target_shape)\n    ssim_value2 = compare_images(cat_pic_1,black_pic, target_shape)\n    ssim_value3 = compare_images(cat_pic_1,white_pic,target_shape)\n    ssim_value4 = compare_images(cat_pic_1,cat_pic_1_same,target_shape)\n    ssim_value5 = compare_images(cat_pic_1,cat_pic_2,target_shape)\n    ssim_value6 = compare_images(dog_pic_1,dog_pic_1_same,target_shape)\n    ssim_value7 = compare_images(dog_pic_1,dog_pic_2,target_shape)\n    \n    \n    \n    ssim\n    print(\"SSIM_cat_dog:\", ssim_value)\n    print(\"SSIM_cat_black:\", ssim_value2)\n    print(\"SSIM_cat_white:\", ssim_value3)\n    print(\"SSIM_cat_same:\", ssim_value4)\n    print(\"SSIM_cat_diff:\", ssim_value5)\n    print(\"SSIM_dog_same:\", ssim_value6)\n    print(\"SSIM_dog_diff:\", ssim_value7)\n\n\n    \n\n\n    # Display the images\n    plt.figure(figsize=(8, 4))\n    plt.subplot(1, 2, 1)\n    plt.imshow(preprocess_image(cat_pic_1, target_shape), cmap='gray')\n    plt.title('Cat Image Resized')\n    plt.subplot(1, 2, 2)\n    plt.imshow(preprocess_image(dog_pic_1, target_shape), cmap='gray')\n    plt.title('Dog Image Resized')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:02.462504Z","iopub.execute_input":"2024-04-14T14:15:02.462797Z","iopub.status.idle":"2024-04-14T14:15:03.257424Z","shell.execute_reply.started":"2024-04-14T14:15:02.462771Z","shell.execute_reply":"2024-04-14T14:15:03.256370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nPSNR experiments start here \n","metadata":{}},{"cell_type":"code","source":"\n\n# Function to add Gaussian noise to an image\ndef add_gaussian_noise(image, noise_level):\n    mean = 0\n    var = noise_level\n    sigma = var ** 0.5\n    noisy_image = image + np.random.normal(mean, sigma, image.shape)\n    return np.clip(noisy_image, 0, 1)\n\n# Function to denoise an image using a Gaussian filter\ndef denoise_gaussian(image, sigma=1):\n    return gaussian(image, sigma=sigma)\n\n# Function to process the image and generate PSNR results and plot\ndef process_image(input_image):\n    # Preprocess the image\n    target_shape = (100, 100)\n    input_image_gray = rgb2gray(input_image)\n    input_image_resized = resize(input_image_gray, target_shape, anti_aliasing=True)\n\n    # Noise levels and results storage\n    noise_levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n    psnr_results = []\n    for i in range (10):\n        psnr_row_results = []\n\n        # Add noise, denoise, and calculate metrics\n        for noise_level in noise_levels:\n            noisy_image = add_gaussian_noise(input_image_resized, noise_level)\n            denoised_image = denoise_gaussian(noisy_image, sigma=1)\n            psnr_value = psnr(input_image_resized, denoised_image)\n            psnr_row_results.append(psnr_value)\n        psnr_results.append(psnr_row_results)\n\n    # Convert noise levels to percentages for plotting\n    noise_percentages = [str(int(level * 100)) + '%' for level in noise_levels]\n\n    # Plotting PSNR values against noise levels\n    plt.figure(figsize=(10, 5))\n    \n    for row_results in psnr_results:\n        plt.plot(noise_percentages, row_results, marker='o', linestyle='--',color = 'lightgray',alpha=0.3)\n        \n    avg_psnr = np.mean(psnr_results, axis=0)\n    plt.plot(noise_percentages, avg_psnr, marker='o',linestyle='--',color='black', label='Average PSNR')\n        \n        \n    plt.title('PSNR values at Different Noise Levels')\n    plt.xlabel('Noise Level')\n    plt.ylabel('PSNR Value')\n    plt.grid(True)\n    plt.show()\n\n    return psnr_results","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:03.258852Z","iopub.execute_input":"2024-04-14T14:15:03.259228Z","iopub.status.idle":"2024-04-14T14:15:03.275355Z","shell.execute_reply.started":"2024-04-14T14:15:03.259193Z","shell.execute_reply":"2024-04-14T14:15:03.274081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Process the images and get PSNR results\ncat_psnr_results = process_image(cat_pic_1)\ndog_psnr_results = process_image(dog_pic_1)\ndog_same_psnr_results= process_image(dog_pic_1_same)\ncat_same_psnr_results= process_image(cat_pic_1_same)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:03.276947Z","iopub.execute_input":"2024-04-14T14:15:03.277317Z","iopub.status.idle":"2024-04-14T14:15:05.024373Z","shell.execute_reply.started":"2024-04-14T14:15:03.277269Z","shell.execute_reply":"2024-04-14T14:15:05.023336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) **Cell Image testing starts here**","metadata":{}},{"cell_type":"code","source":"\nimport subplots from matplotlib\nprint(\"Shape of clean_test_images:\", clean_test_images.shape)\n\n\n# Visualize the first few images\nfig, axes = plt.subplots(1, 5, figsize=(15, 5))\nfor i, ax in enumerate(axes):\n    ax.imshow(clean_test_images[i], cmap='gray')\n    ax.set_title(f\"Image {i+1}\")\n    ax.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:11:28.771311Z","iopub.execute_input":"2024-04-16T22:11:28.771730Z","iopub.status.idle":"2024-04-16T22:11:28.779654Z","shell.execute_reply.started":"2024-04-16T22:11:28.771684Z","shell.execute_reply":"2024-04-16T22:11:28.778263Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import subplots from matplotlib\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3875639140.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"clean_train_images = np.load('/kaggle/input/denoising-data/clean_train.npy')\n\nprint(\"Shape of clean_train_images:\", clean_train_images.shape)\n\n\n# Visualize the first few images\nfig, axes = plt.subplots(1, 5, figsize=(15, 5))\nfor i, ax in enumerate(axes):\n    ax.imshow(clean_train_images[i], cmap='gray')\n    ax.set_title(f\"Image {i+1}\")\n    ax.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:15:11.025921Z","iopub.execute_input":"2024-04-14T14:15:11.026248Z","iopub.status.idle":"2024-04-14T14:15:47.284751Z","shell.execute_reply.started":"2024-04-14T14:15:11.026209Z","shell.execute_reply":"2024-04-14T14:15:47.283795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_test_images = np.load('/kaggle/input/denoising-data/noise_test.npy')\n\n\nprint(\"Shape of noise_test_images:\", noise_train_images.shape)\n\n\n# Visualize the first few images\nfig, axes = plt.subplots(1, 5, figsize=(15, 5))\nfor i, ax in enumerate(axes):\n    ax.imshow(noise_test_images[i], cmap='gray')\n    ax.set_title(f\"Image {i+1}\")\n    ax.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:10:31.541003Z","iopub.execute_input":"2024-04-16T22:10:31.541723Z","iopub.status.idle":"2024-04-16T22:10:32.068430Z","shell.execute_reply.started":"2024-04-16T22:10:31.541671Z","shell.execute_reply":"2024-04-16T22:10:32.066938Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Shape of noise_test_images: (41520, 256, 256)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of noise_test_images:\u001b[39m\u001b[38;5;124m\"\u001b[39m, noise_train_images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize the first few images\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axes):\n\u001b[1;32m      7\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(noise_test_images[i], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/_api/__init__.py:226\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'subplots'"],"ename":"AttributeError","evalue":"module 'matplotlib' has no attribute 'subplots'","output_type":"error"}]},{"cell_type":"code","source":"noisy_image = noise_train_images[0]\nclean_image = clean_train_images[0]\n\ndef compare_images(image1, image2, target_shape):\n    image1_resized = resize(image1, target_shape, anti_aliasing=True)\n    image2_resized = resize(image2, target_shape, anti_aliasing=True)\n    ssim_value = ssim(image1_resized, image2_resized, data_range=image2_resized.max() - image2_resized.min())\n    return ssim_value\n\n\ntarget_shape = (256, 256)  # Assuming your images are 256x256 pixels\nssim_value = compare_images(noisy_image, clean_image, target_shape)\nprint(\"SSIM between the first noisy and clean image:\", ssim_value)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:29.163126Z","iopub.execute_input":"2024-04-14T14:16:29.163418Z","iopub.status.idle":"2024-04-14T14:16:29.182874Z","shell.execute_reply.started":"2024-04-14T14:16:29.163393Z","shell.execute_reply":"2024-04-14T14:16:29.181843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noisy_test_image = noise_test_images[0]\nclean_test_image = clean_test_images[0]\n\ndef compare_images(image1, image2, target_shape):\n    image1_resized = resize(image1, target_shape, anti_aliasing=True)\n    image2_resized = resize(image2, target_shape, anti_aliasing=True)\n    ssim_value = ssim(image1_resized, image2_resized, data_range=image2_resized.max() - image2_resized.min())\n    return ssim_value\n\n\ntarget_shape = (256, 256)  # Assuming your images are 256x256 pixels\nssim_value = compare_images(noisy_test_image, clean_test_image, target_shape)\nprint(\"SSIM between the first noisy and clean image:\", ssim_value)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:29.183946Z","iopub.execute_input":"2024-04-14T14:16:29.184245Z","iopub.status.idle":"2024-04-14T14:16:29.203744Z","shell.execute_reply.started":"2024-04-14T14:16:29.184220Z","shell.execute_reply":"2024-04-14T14:16:29.202881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef calculate_psnr(image1, image2):\n    return psnr(image1, image2)\n\npsnr_value = calculate_psnr(noisy_test_image, clean_test_image)\nprint(f\"PSNR: {psnr_value}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:29.204847Z","iopub.execute_input":"2024-04-14T14:16:29.205459Z","iopub.status.idle":"2024-04-14T14:16:29.211778Z","shell.execute_reply.started":"2024-04-14T14:16:29.205426Z","shell.execute_reply":"2024-04-14T14:16:29.210849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psnr_train = [calculate_psnr(clean, noise) for clean, noise in zip(clean_train_images, noise_train_images)]\npsnr_test = [calculate_psnr(clean, noise) for clean, noise in zip(clean_test_images, noise_test_images)]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:29.212842Z","iopub.execute_input":"2024-04-14T14:16:29.213110Z","iopub.status.idle":"2024-04-14T14:16:42.349173Z","shell.execute_reply.started":"2024-04-14T14:16:29.213087Z","shell.execute_reply":"2024-04-14T14:16:42.348352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_psnr_train = np.mean(psnr_train)\nvariance_psnr_train = np.var(psnr_train)\nstd_psrn_train = np.std(psnr_train)\n\nmean_psnr_test = np.mean(psnr_test)\nvariance_psnr_test = np.var(psnr_test)\nstd_psrn_test = np.std(psnr_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:42.350368Z","iopub.execute_input":"2024-04-14T14:16:42.350721Z","iopub.status.idle":"2024-04-14T14:16:42.368075Z","shell.execute_reply.started":"2024-04-14T14:16:42.350689Z","shell.execute_reply":"2024-04-14T14:16:42.367101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train PSNR - Mean: {mean_psnr_train}, Variance: {variance_psnr_train}, \")\nprint(f\"Test PSNR - Mean: {mean_psnr_test}, Variance: {variance_psnr_test}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T14:16:42.369496Z","iopub.execute_input":"2024-04-14T14:16:42.369859Z","iopub.status.idle":"2024-04-14T14:16:42.375287Z","shell.execute_reply.started":"2024-04-14T14:16:42.369827Z","shell.execute_reply":"2024-04-14T14:16:42.374241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  4) Running sample inferences on the given pre trained model \n****","metadata":{}},{"cell_type":"markdown","source":"Importing all the necessary libraries","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nfrom torch import nn\nimport numpy as np \nimport matplotlib as plt\nfrom tqdm import tqdm\nfrom skimage.metrics import peak_signal_noise_ratio, structural_similarity\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:07:17.287116Z","iopub.execute_input":"2024-04-17T00:07:17.287470Z","iopub.status.idle":"2024-04-17T00:07:22.359087Z","shell.execute_reply.started":"2024-04-17T00:07:17.287442Z","shell.execute_reply":"2024-04-17T00:07:22.357825Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Loading the data\nnoise_test_images = np.load('/kaggle/input/denoising-data/noise_test.npy')\n\n# Converting the data to PyTorch tensors\nnoise_test_tensor = torch.from_numpy(noise_test_images.astype(np.float32))\n\nnoise_test_images = np.load('/kaggle/input/denoising-data/clean_test.npy')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:09:32.907435Z","iopub.execute_input":"2024-04-17T00:09:32.908128Z","iopub.status.idle":"2024-04-17T00:09:33.564470Z","shell.execute_reply.started":"2024-04-17T00:09:32.908095Z","shell.execute_reply":"2024-04-17T00:09:33.563325Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Adding an extra dimension to represent the color channel\nnoise_test_tensor = noise_test_tensor.unsqueeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:11:11.151844Z","iopub.execute_input":"2024-04-17T00:11:11.152595Z","iopub.status.idle":"2024-04-17T00:11:11.164276Z","shell.execute_reply.started":"2024-04-17T00:11:11.152561Z","shell.execute_reply":"2024-04-17T00:11:11.162959Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"noise_test_tensor.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:11:13.600477Z","iopub.execute_input":"2024-04-17T00:11:13.601210Z","iopub.status.idle":"2024-04-17T00:11:13.608254Z","shell.execute_reply.started":"2024-04-17T00:11:13.601175Z","shell.execute_reply":"2024-04-17T00:11:13.607091Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([5200, 1, 256, 256])"},"metadata":{}}]},{"cell_type":"code","source":"# Moving tensors to the GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnoise_test_tensor = noise_test_tensor.to(device)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:11:23.418000Z","iopub.execute_input":"2024-04-17T00:11:23.418369Z","iopub.status.idle":"2024-04-17T00:11:23.423982Z","shell.execute_reply.started":"2024-04-17T00:11:23.418342Z","shell.execute_reply":"2024-04-17T00:11:23.422739Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Loading all the required data and converting them to tensors so we can use them for ML model inferences quicker computations","metadata":{}},{"cell_type":"code","source":"print(noise_test_images.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:11:28.982587Z","iopub.execute_input":"2024-04-17T00:11:28.983233Z","iopub.status.idle":"2024-04-17T00:11:28.988493Z","shell.execute_reply.started":"2024-04-17T00:11:28.983194Z","shell.execute_reply":"2024-04-17T00:11:28.987381Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(5200, 256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(noise_train_images.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T18:36:54.382803Z","iopub.execute_input":"2024-04-16T18:36:54.383587Z","iopub.status.idle":"2024-04-16T18:36:54.389213Z","shell.execute_reply.started":"2024-04-16T18:36:54.383546Z","shell.execute_reply":"2024-04-16T18:36:54.388259Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(41520, 256, 256)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Define the architercture of the RatUNet model ","metadata":{}},{"cell_type":"code","source":"class RatUNet(nn.Module):\n    def __init__(self, block, num_features=64):\n        super(RatUNet, self).__init__()  # Call the constructor of the parent class (nn.Module) to initialize the base class\n        self.inplanes = num_features  # Set the initial number of feature planes to num_features (default is 64)\n        \n        self.conv = nn.Conv2d(1, num_features, kernel_size=3, stride=1, padding=1, bias=True)  # Define the initial 2D convolution layer with 1 input channel, num_features output channels, 3x3 kernel size, stride 1, and padding 1\n\n        self.layer1 = self._make_layer(block, 64, 128, 3, stride=2)  # Call the _make_layer function to create the first layer with 64 input channels, 128 output channels, 3 blocks, and stride 2\n        self.layer2 = self._make_layer(block, 128, 256, 3, stride=2)  # Call the _make_layer function to create the second layer with 128 input channels, 256 output channels, 3 blocks, and stride 2\n\n        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)  # Define the first transposed 2D convolution (deconvolution) layer with 512 input channels, 256 output channels, 3x3 kernel size, stride 2, padding 1, output padding 1, and no bias\n        self.layer3 = self._make_layer(block, 256, 512, 4, stride=2)  # Call the _make_layer function to create the third layer with 256 input channels, 512 output channels, 4 blocks, and stride 2\n        self.deconv2 = nn.ConvTranspose2d(512, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)  # Define the second deconvolution layer with 512 input channels, 128 output channels, 3x3 kernel size, stride 2, padding 1, output padding 1, and no bias\n        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)  # Define the third deconvolution layer with 256 input channels, 128 output channels, 3x3 kernel size, stride 2, padding 1, output padding 1, and no bias\n\n        self.layer4 = self._make_layer(block, 256, 256, 3)  # Call the _make_layer function to create the fourth layer with 256 input channels, 256 output channels, and 3 blocks\n        self.layer5 = self._make_layer(block, 128, 128, 3)  # Call the _make_layer function to create the fifth layer with 128 input channels, 128 output channels, and 3 blocks\n        self.layer6 = self._make_layer(block, 128, 128, 2)  # Call the _make_layer function to create the sixth layer with 128 input channels, 128 output channels, and 2 blocks\n        self.conv2 = nn.Sequential(  # Define a sequence of convolutional layers\n            nn.Conv2d(192, 128, kernel_size=3, stride=1, padding=1, bias=True),  # 2D convolution with 192 input channels, 128 output channels, 3x3 kernel size, stride 1, padding 1, and bias\n            nn.PReLU(),  # Parametric Rectified Linear Unit (PReLU) activation function\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),  # 2D convolution with 128 input channels, 128 output channels, 3x3 kernel size, stride 1, padding 1, and bias\n            nn.PReLU(),  # Parametric Rectified Linear Unit (PReLU) activation function\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True),  # 2D convolution with 128 input channels, 128 output channels, 3x3 kernel size, stride 1, padding 1, and bias\n            nn.PReLU(),  # Parametric Rectified Linear Unit (PReLU) activation function\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=True),  # 2D depthwise convolution with 128 input channels, 128 output channels, 3x3 kernel size, stride 1, padding 1, and bias\n            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True),  # 2D convolution with 128 input channels, 128 output channels, 1x1 kernel size, stride 1, no padding, and bias\n            nn.ReLU(inplace=True),  # Rectified Linear Unit (ReLU) activation function with inplace computation\n        )\n        self.ca = SequentialPolarizedSelfAttention(128)  # Define the channel attention module with 128 channels\n        self.lastconv = nn.Conv2d(128, 1, kernel_size=3, stride=1, padding=1, bias=True)  # Define the final 2D convolution layer with 128 input channels, 1 output channel, 3x3 kernel size, stride 1, padding 1, and bias\n\n        # Weight initialization\n        for m in self.modules():  # Loop over all submodules\n            if isinstance(m, nn.Conv2d):  # Check if the submodule is a 2D convolution layer\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels  # Calculate the number of weights in the convolution layer\n                m.weight.data.normal_(0.0, math.sqrt(1.0 / n))  # Initialize the weights with a normal distribution with mean 0 and standard deviation sqrt(1/n)\n                m.bias.data.zero_()  # Initialize the bias with zeros\n\n    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n        layers = []\n        downsample = None\n        self.inplanes = inplanes\n        if stride != 1:\n            downsample = nn.Sequential(\n                    nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, bias=True),\n                    nn.AvgPool2d(kernel_size=2, stride=stride),\n            )\n#        if  stride == 1 and self.inplanes == 2*planes:\n#            downsample = nn.Sequential(\n#                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=1, bias=True),\n#                #nn.BatchNorm2d(planes)\n#            )\n        \n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        \n        res = self.conv(x)\n\n        res2 = self.layer1(res)\n        res3 = self.layer2(res2)        \n        out = self.layer3(res3)\n        \n        out = self.deconv1(out)               \n        out = self.layer4(out)\n        out = torch.cat((out, res3), dim=1) \n\n        out = self.deconv2(out)        \n        out = self.layer5(out)\n        out = torch.cat((out, res2), dim=1)\n        \n        out = self.deconv3(out)        \n        out = self.layer6(out)\n        out = torch.cat((out, res), dim=1)\n        \n        out = self.conv2(out)\n        out = self.ca(out)\n        out = self.lastconv(out)\n        \n        return x - out\n\nclass BasicBlock(nn.Module):\n    expansion=1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride = stride, padding=1, bias=True)\n        #self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.PReLU()#.LeakyReLU(0.2, inplace=True)# nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride = 1, padding=1, bias=True)\n        #self.conv3 = nn.Conv2d(planes, planes, kernel_size=1, stride = 1, padding=0, bias=True)\n\n        self.downsample = downsample\n        #self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        #out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)        \n        \n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual      \n        out = self.relu(out)\n\n        return out\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n           \n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=True),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=True))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=True)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n    \nclass SequentialPolarizedSelfAttention(nn.Module):\n\n    def __init__(self, channel=512):\n        super().__init__()\n        self.ch_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n        self.ch_wq=nn.Conv2d(channel,1,kernel_size=(1,1))\n        self.softmax_channel=nn.Softmax(1)\n        self.softmax_spatial=nn.Softmax(-1)\n        self.ch_wz=nn.Conv2d(channel//2,channel,kernel_size=(1,1))\n        self.ln=nn.LayerNorm(channel)\n        self.sigmoid=nn.Sigmoid()\n        self.sp_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n        self.sp_wq=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n        self.agp=nn.AdaptiveAvgPool2d((1,1))\n\n    def forward(self, x):\n        b, c, h, w = x.size()\n\n        #Channel-only Self-Attention\n        channel_wv=self.ch_wv(x) #bs,c//2,h,w\n        channel_wq=self.ch_wq(x) #bs,1,h,w\n        channel_wv=channel_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n        channel_wq=channel_wq.reshape(b,-1,1) #bs,h*w,1\n        channel_wq=self.softmax_channel(channel_wq)\n        channel_wz=torch.matmul(channel_wv,channel_wq).unsqueeze(-1) #bs,c//2,1,1\n        channel_weight=self.sigmoid(self.ch_wz(channel_wz).reshape(b,c,1).permute(0,2,1)).permute(0,2,1).reshape(b,c,1,1) #bs,c,1,1self.ln(\n        channel_out=channel_weight*x\n\n        #Spatial-only Self-Attention\n        spatial_wv=self.sp_wv(channel_out) #bs,c//2,h,w\n        spatial_wq=self.sp_wq(channel_out) #bs,c//2,h,w\n        spatial_wq=self.agp(spatial_wq) #bs,c//2,1,1\n        spatial_wv=spatial_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n        spatial_wq=spatial_wq.permute(0,2,3,1).reshape(b,1,c//2) #bs,1,c//2\n        spatial_wq=self.softmax_spatial(spatial_wq)\n        spatial_wz=torch.matmul(spatial_wq,spatial_wv) #bs,1,h*w\n        spatial_weight=self.sigmoid(spatial_wz.reshape(b,1,h,w)) #bs,1,h,w\n        spatial_out=spatial_weight*channel_out\n        return spatial_out","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:12:05.863623Z","iopub.execute_input":"2024-04-17T00:12:05.864017Z","iopub.status.idle":"2024-04-17T00:12:05.927379Z","shell.execute_reply.started":"2024-04-17T00:12:05.863987Z","shell.execute_reply":"2024-04-17T00:12:05.926265Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-16T21:20:49.249975Z","iopub.execute_input":"2024-04-16T21:20:49.250653Z","iopub.status.idle":"2024-04-16T21:22:13.244423Z","shell.execute_reply.started":"2024-04-16T21:20:49.250620Z","shell.execute_reply":"2024-04-16T21:22:13.243282Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torch.cuda.get_device_name(torch.cuda.current_device())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:21:01.041532Z","iopub.execute_input":"2024-04-16T22:21:01.042905Z","iopub.status.idle":"2024-04-16T22:21:01.050072Z","shell.execute_reply.started":"2024-04-16T22:21:01.042857Z","shell.execute_reply":"2024-04-16T22:21:01.048978Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'Tesla T4'"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = torch.load('/kaggle/input/model_epoch_100.pth/pytorch/version1/1/model_epoch_100.pth', map_location=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:12:13.353254Z","iopub.execute_input":"2024-04-17T00:12:13.353698Z","iopub.status.idle":"2024-04-17T00:12:13.500888Z","shell.execute_reply.started":"2024-04-17T00:12:13.353664Z","shell.execute_reply":"2024-04-17T00:12:13.499776Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def process_in_batches(model, data_tensor, batch_size=64):\n    model.eval()  # Ensure the model is in evaluation mode\n    denoised_images = []\n    num_batches = int(np.ceil(data_tensor.size(0) / batch_size))\n    print(f\"Processing {num_batches} batches...\")\n    \n    with torch.no_grad():  # Disables gradient calculation\n        for i in tqdm(range(num_batches), desc=\"Denoising\"):\n            batch_start = i * batch_size\n            batch_end = min((i + 1) * batch_size, data_tensor.size(0))\n            batch = data_tensor[batch_start:batch_end].to(device, non_blocking=True)  # Move batch to GPU\n            \n            # Reshape the batch to have a single channel and the correct spatial dimensions\n            batch = batch.view(batch.size(0), 1, batch.size(2), batch.size(2))\n            \n            print(f\"Batch {i+1}: Device - {batch.device}, Size - {batch.size()}\")\n            denoised_batch = model(batch)\n            denoised_images.append(denoised_batch.detach().cpu().numpy())  # Move results back to CPU\n            torch.cuda.empty_cache()  # Clear unused memory after processing each batch\n    \n    return np.concatenate(denoised_images, axis=0)\n\n# Processing the training and test data\ndenoised_test_images = process_in_batches(model, noise_test_tensor, batch_size=64)\n\n# Saving the denoised images as .npy files\nnp.save('/kaggle/working/denoised_test_images.npy', denoised_test_images)\n\n/kaggle/input/denoising-data","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:12:22.758203Z","iopub.execute_input":"2024-04-17T00:12:22.758884Z","iopub.status.idle":"2024-04-17T00:15:20.270093Z","shell.execute_reply.started":"2024-04-17T00:12:22.758836Z","shell.execute_reply":"2024-04-17T00:15:20.269141Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Processing 82 batches...\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   0%|          | 0/82 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 1: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   1%|          | 1/82 [00:04<05:54,  4.37s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 2: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   2%|▏         | 2/82 [00:06<04:03,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 3: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   4%|▎         | 3/82 [00:08<03:22,  2.56s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 4: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   5%|▍         | 4/82 [00:10<03:04,  2.37s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 5: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   6%|▌         | 5/82 [00:12<02:53,  2.26s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 6: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   7%|▋         | 6/82 [00:14<02:45,  2.18s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 7: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:   9%|▊         | 7/82 [00:16<02:40,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 8: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  10%|▉         | 8/82 [00:18<02:36,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 9: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  11%|█         | 9/82 [00:20<02:34,  2.11s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 10: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  12%|█▏        | 10/82 [00:22<02:31,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 11: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  13%|█▎        | 11/82 [00:25<02:29,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 12: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  15%|█▍        | 12/82 [00:27<02:26,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 13: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  16%|█▌        | 13/82 [00:29<02:23,  2.08s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 14: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  17%|█▋        | 14/82 [00:31<02:22,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 15: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  18%|█▊        | 15/82 [00:33<02:20,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 16: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  20%|█▉        | 16/82 [00:35<02:18,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 17: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  21%|██        | 17/82 [00:37<02:15,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 18: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  22%|██▏       | 18/82 [00:39<02:13,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 19: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  23%|██▎       | 19/82 [00:41<02:11,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 20: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  24%|██▍       | 20/82 [00:43<02:09,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 21: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  26%|██▌       | 21/82 [00:45<02:05,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 22: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  27%|██▋       | 22/82 [00:47<02:04,  2.07s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 23: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  28%|██▊       | 23/82 [00:50<02:02,  2.08s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 24: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  29%|██▉       | 24/82 [00:52<02:01,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 25: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  30%|███       | 25/82 [00:54<01:59,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 26: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  32%|███▏      | 26/82 [00:56<01:57,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 27: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  33%|███▎      | 27/82 [00:58<01:55,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 28: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  34%|███▍      | 28/82 [01:00<01:53,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 29: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  35%|███▌      | 29/82 [01:02<01:51,  2.10s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 30: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  37%|███▋      | 30/82 [01:04<01:50,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 31: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  38%|███▊      | 31/82 [01:06<01:48,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 32: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  39%|███▉      | 32/82 [01:09<01:45,  2.11s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 33: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  40%|████      | 33/82 [01:11<01:43,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 34: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  41%|████▏     | 34/82 [01:13<01:41,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 35: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  43%|████▎     | 35/82 [01:15<01:41,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 36: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  44%|████▍     | 36/82 [01:17<01:39,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 37: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  45%|████▌     | 37/82 [01:19<01:36,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 38: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  46%|████▋     | 38/82 [01:21<01:34,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 39: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  48%|████▊     | 39/82 [01:24<01:32,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 40: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  49%|████▉     | 40/82 [01:26<01:30,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 41: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  50%|█████     | 41/82 [01:28<01:28,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 42: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  51%|█████     | 42/82 [01:30<01:26,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 43: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  52%|█████▏    | 43/82 [01:32<01:23,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 44: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  54%|█████▎    | 44/82 [01:34<01:22,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 45: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  55%|█████▍    | 45/82 [01:37<01:20,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 46: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  56%|█████▌    | 46/82 [01:39<01:17,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 47: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  57%|█████▋    | 47/82 [01:41<01:16,  2.18s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 48: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  59%|█████▊    | 48/82 [01:43<01:13,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 49: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  60%|█████▉    | 49/82 [01:45<01:11,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 50: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  61%|██████    | 50/82 [01:47<01:09,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 51: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  62%|██████▏   | 51/82 [01:49<01:06,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 52: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  63%|██████▎   | 52/82 [01:52<01:04,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 53: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  65%|██████▍   | 53/82 [01:54<01:02,  2.14s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 54: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  66%|██████▌   | 54/82 [01:56<00:59,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 55: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  67%|██████▋   | 55/82 [01:58<00:57,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 56: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  68%|██████▊   | 56/82 [02:00<00:55,  2.13s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 57: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  70%|██████▉   | 57/82 [02:02<00:53,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 58: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  71%|███████   | 58/82 [02:04<00:51,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 59: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  72%|███████▏  | 59/82 [02:07<00:49,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 60: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  73%|███████▎  | 60/82 [02:09<00:47,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 61: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  74%|███████▍  | 61/82 [02:11<00:45,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 62: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  76%|███████▌  | 62/82 [02:13<00:43,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 63: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  77%|███████▋  | 63/82 [02:15<00:41,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 64: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  78%|███████▊  | 64/82 [02:17<00:39,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 65: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  79%|███████▉  | 65/82 [02:20<00:36,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 66: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  80%|████████  | 66/82 [02:22<00:34,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 67: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  82%|████████▏ | 67/82 [02:24<00:32,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 68: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  83%|████████▎ | 68/82 [02:26<00:30,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 69: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  84%|████████▍ | 69/82 [02:28<00:28,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 70: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  85%|████████▌ | 70/82 [02:30<00:25,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 71: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  87%|████████▋ | 71/82 [02:33<00:23,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 72: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  88%|████████▊ | 72/82 [02:35<00:21,  2.17s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 73: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  89%|████████▉ | 73/82 [02:37<00:19,  2.16s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 74: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  90%|█████████ | 74/82 [02:39<00:17,  2.18s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 75: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  91%|█████████▏| 75/82 [02:41<00:15,  2.19s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 76: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  93%|█████████▎| 76/82 [02:44<00:13,  2.20s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 77: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  94%|█████████▍| 77/82 [02:46<00:11,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 78: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  95%|█████████▌| 78/82 [02:48<00:08,  2.19s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 79: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  96%|█████████▋| 79/82 [02:50<00:06,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 80: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  98%|█████████▊| 80/82 [02:53<00:04,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 81: Device - cuda:0, Size - torch.Size([64, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising:  99%|█████████▉| 81/82 [02:55<00:02,  2.22s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 82: Device - cuda:0, Size - torch.Size([16, 1, 256, 256])\n","output_type":"stream"},{"name":"stderr","text":"Denoising: 100%|██████████| 82/82 [02:55<00:00,  2.14s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(noise_test_tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:10:48.294570Z","iopub.execute_input":"2024-04-17T00:10:48.295014Z","iopub.status.idle":"2024-04-17T00:10:48.300948Z","shell.execute_reply.started":"2024-04-17T00:10:48.294982Z","shell.execute_reply":"2024-04-17T00:10:48.299791Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"torch.Size([5200, 256, 256])\n","output_type":"stream"}]},{"cell_type":"code","source":"denoised_test_images = np.load('/kaggle/working/denoised_test_images.npy')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:33:50.387990Z","iopub.execute_input":"2024-04-17T00:33:50.388380Z","iopub.status.idle":"2024-04-17T00:33:50.832458Z","shell.execute_reply.started":"2024-04-17T00:33:50.388352Z","shell.execute_reply":"2024-04-17T00:33:50.831507Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#need to remove the colour channel \ndenoised_test_images_modified = np.squeeze(denoised_test_images, axis=1)\nprint(denoised_test_images_modified.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:50:44.100088Z","iopub.execute_input":"2024-04-17T00:50:44.100495Z","iopub.status.idle":"2024-04-17T00:50:44.106944Z","shell.execute_reply.started":"2024-04-17T00:50:44.100461Z","shell.execute_reply":"2024-04-17T00:50:44.105835Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(5200, 256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(denoised_test_images.shape)\nprint (clean_test_images.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:50:48.724451Z","iopub.execute_input":"2024-04-17T00:50:48.724849Z","iopub.status.idle":"2024-04-17T00:50:48.731241Z","shell.execute_reply.started":"2024-04-17T00:50:48.724816Z","shell.execute_reply":"2024-04-17T00:50:48.729818Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"(5200, 1, 256, 256)\n(5200, 256, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading the data\nclean_test_images = np.load('/kaggle/input/denoising-data/clean_test.npy')\n\n\n\n\ndef calculate_metrics(denoised_images, clean_images):\n    psnr_values = []\n    ssim_values = []\n    \n    for denoised, clean in zip(denoised_images, clean_images):\n        psnr = peak_signal_noise_ratio(clean, denoised)\n        psnr_values.append(psnr)\n    \n    return np.mean(psnr_values)\n\ntest_psnr= calculate_metrics(denoised_test_images_modified, clean_test_images)\nprint(f\"Test Data - PSNR: {test_psnr:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T00:57:35.522323Z","iopub.execute_input":"2024-04-17T00:57:35.522726Z","iopub.status.idle":"2024-04-17T00:57:37.550580Z","shell.execute_reply.started":"2024-04-17T00:57:35.522694Z","shell.execute_reply":"2024-04-17T00:57:37.549290Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2440740897.py:12: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n  psnr = peak_signal_noise_ratio(clean, denoised)\n","output_type":"stream"},{"name":"stdout","text":"Test Data - PSNR: 55.6101\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_ssim(denoised_images, clean_images):\n    ssim_values = []\n    \n    # Iterate over the pairs of denoised and clean images\n    for denoised, clean in zip(denoised_images, clean_images):\n        # Squeeze to remove unnecessary singleton dimensions if present\n        denoised = np.squeeze(denoised)\n        clean = np.squeeze(clean)\n        \n        # Calculate SSIM, specify data_range if known (e.g., 1.0 for images with pixels in [0,1])\n        ssim = structural_similarity(denoised, clean, data_range=clean.max() - clean.min())\n        ssim_values.append(ssim)\n    \n    return ssim_values\n\ndef main():\n    \n    # Calculate SSIM for each image pair\n    ssim_values = calculate_ssim(denoised_test_images_modified, clean_test_images)\n    \n    # Output the average SSIM\n    average_ssim = np.mean(ssim_values)\n    print(f\"Average SSIM: {average_ssim:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:34:52.357914Z","iopub.execute_input":"2024-04-17T01:34:52.358616Z","iopub.status.idle":"2024-04-17T01:35:13.696142Z","shell.execute_reply.started":"2024-04-17T01:34:52.358585Z","shell.execute_reply":"2024-04-17T01:35:13.695016Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Average SSIM: 0.4746\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    \n    # Calculate SSIM for each image pair\n    ssim_values = calculate_ssim(denoised_test_images_modified, clean_test_images)\n    \n    # Output the average SSIM\n    average_ssim = np.mean(ssim_values)\n    print(f\"Average SSIM: {average_ssim:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:34.914043Z","iopub.execute_input":"2024-04-17T01:41:34.914412Z","iopub.status.idle":"2024-04-17T01:41:56.164971Z","shell.execute_reply.started":"2024-04-17T01:41:34.914381Z","shell.execute_reply":"2024-04-17T01:41:56.164027Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Average SSIM: 0.4746\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    \n    # Calculate SSIM for each image pair\n    ssim_values = calculate_ssim(noise_test_images, clean_test_images)\n    \n    # Output the average SSIM\n    average_ssim = np.mean(ssim_values)\n    print(f\"Average SSIM: {average_ssim:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:40:35.630797Z","iopub.execute_input":"2024-04-17T01:40:35.631159Z","iopub.status.idle":"2024-04-17T01:41:01.195830Z","shell.execute_reply.started":"2024-04-17T01:40:35.631133Z","shell.execute_reply":"2024-04-17T01:41:01.194884Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Average SSIM: 0.4746\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T22:38:53.381691Z","iopub.execute_input":"2024-04-14T22:38:53.382576Z","iopub.status.idle":"2024-04-14T22:38:56.154341Z","shell.execute_reply.started":"2024-04-14T22:38:53.382543Z","shell.execute_reply":"2024-04-14T22:38:56.153355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-15T02:26:23.888437Z","iopub.execute_input":"2024-04-15T02:26:23.889188Z","iopub.status.idle":"2024-04-15T02:26:24.129051Z","shell.execute_reply.started":"2024-04-15T02:26:23.889155Z","shell.execute_reply":"2024-04-15T02:26:24.127858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-15T02:37:55.905795Z","iopub.execute_input":"2024-04-15T02:37:55.906469Z","iopub.status.idle":"2024-04-15T02:37:55.914341Z","shell.execute_reply.started":"2024-04-15T02:37:55.906435Z","shell.execute_reply":"2024-04-15T02:37:55.913298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T02:38:42.377986Z","iopub.execute_input":"2024-04-15T02:38:42.378660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T22:03:27.479160Z","iopub.execute_input":"2024-04-14T22:03:27.480036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:45:26.853400Z","iopub.execute_input":"2024-04-14T21:45:26.854432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:03:08.553858Z","iopub.execute_input":"2024-04-14T21:03:08.554237Z","iopub.status.idle":"2024-04-14T21:03:13.450449Z","shell.execute_reply.started":"2024-04-14T21:03:08.554205Z","shell.execute_reply":"2024-04-14T21:03:13.449153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T07:54:12.068045Z","iopub.execute_input":"2024-04-15T07:54:12.068930Z","iopub.status.idle":"2024-04-15T07:54:12.073691Z","shell.execute_reply.started":"2024-04-15T07:54:12.068872Z","shell.execute_reply":"2024-04-15T07:54:12.072771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:55:02.984794Z","iopub.execute_input":"2024-04-16T04:55:02.985192Z","iopub.status.idle":"2024-04-16T04:55:02.996145Z","shell.execute_reply.started":"2024-04-16T04:55:02.985162Z","shell.execute_reply":"2024-04-16T04:55:02.995225Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"tensor(6.4000)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]}]}